{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "##准备： 安装依赖"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29dd1b3a551bee6e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 安装千问的依赖\n",
    "!cd Qwen-7b\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# 安装 langchain 相关依赖\n",
    "!pip install langchain google-search-results wolframalpha arxiv tiktoken einops transformers_stream_generator accelerate"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-12T14:58:32.439649Z",
     "start_time": "2024-01-12T14:58:32.431714Z"
    }
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 导入 LangChain 的工具"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ccda9b5bc22b651"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain import SerpAPIWrapper\n",
    "from langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper\n",
    "from langchain.utilities import ArxivAPIWrapper\n",
    "from langchain.tools.python.tool import PythonAstREPLTool\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "import os\n",
    "import json\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "\n",
    "# 为了使用谷歌搜索（SERPAPI）， WolframAlpha，您需要自行申请它们的 API KEY，然后填入此处\n",
    "# os.environ['SERPAPI_API_KEY'] = '重要！请在这里填入您的 SERPAPI_API_KEY！'\n",
    "os.environ['SERPAPI_API_KEY'] = '0604eae617e14a9dcd9ca26e860c6eaf07867039675ca79340ead0ceebfe22d0'\n",
    "# os.environ['WOLFRAM_ALPHA_APPID'] = '重要！请在这里填入您的 WOLFRAM_ALPHA_APPID！'\n",
    "os.environ['WOLFRAM_ALPHA_APPID'] = 'V2H6J6-JYQAJLURE4'\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "WolframAlpha = WolframAlphaAPIWrapper()\n",
    "arxiv = ArxivAPIWrapper()\n",
    "python=PythonAstREPLTool()\n",
    "\n",
    "def tool_wrapper_for_qwen(tool):\n",
    "    def tool_(query):\n",
    "        print(query)\n",
    "        query = json.loads(query)[\"query\"]\n",
    "        return tool.run(query)\n",
    "    return tool_\n",
    "\n",
    "# 以下是给千问看的工具描述：\n",
    "TOOLS = [\n",
    "    {\n",
    "        'name_for_human':\n",
    "            'google search',\n",
    "        'name_for_model':\n",
    "            'Search',\n",
    "        'description_for_model':\n",
    "            'useful for when you need to answer questions about current events.',\n",
    "        'parameters': [{\n",
    "            \"name\": \"query\",\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"search query of google\",\n",
    "            'required': True\n",
    "        }], \n",
    "        'tool_api': tool_wrapper_for_qwen(search)\n",
    "    },\n",
    "    {\n",
    "        'name_for_human':\n",
    "            'Wolfram Alpha',\n",
    "        'name_for_model':\n",
    "            'Math',\n",
    "        'description_for_model':\n",
    "            'Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life.',\n",
    "        'parameters': [{\n",
    "            \"name\": \"query\",\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"the problem to solved by Wolfram Alpha\",\n",
    "            'required': True\n",
    "        }], \n",
    "        'tool_api': tool_wrapper_for_qwen(WolframAlpha)\n",
    "    },  \n",
    "    {\n",
    "        'name_for_human':\n",
    "            'arxiv',\n",
    "        'name_for_model':\n",
    "            'Arxiv',\n",
    "        'description_for_model':\n",
    "            'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org.',\n",
    "        'parameters': [{\n",
    "            \"name\": \"query\",\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"the document id of arxiv to search\",\n",
    "            'required': True\n",
    "        }], \n",
    "        'tool_api': tool_wrapper_for_qwen(arxiv)\n",
    "    },\n",
    "    {\n",
    "        'name_for_human':\n",
    "            'python',\n",
    "        'name_for_model':\n",
    "            'python',\n",
    "        'description_for_model':\n",
    "            \"A Python shell. Use this to execute python commands. When using this tool, sometimes output is abbreviated - Make sure it does not look abbreviated before using it in your answer. \"\n",
    "            \"Don't add comments to your python code.\",\n",
    "        'parameters': [{\n",
    "            \"name\": \"query\",\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"a valid python command.\",\n",
    "            'required': True\n",
    "        }],\n",
    "        'tool_api': tool_wrapper_for_qwen(python)\n",
    "    }\n",
    "\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T15:12:12.653278Z",
     "start_time": "2024-01-14T15:12:12.042352Z"
    }
   },
   "id": "39e004c3582068bd",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 让千问判断调用什么工具，生成工具入参"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57a4e5c7685b2752"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Search: Call this tool to interact with the google search API. What is the google search API useful for? useful for when you need to answer questions about current events. Parameters: [{\"name\": \"query\", \"type\": \"string\", \"description\": \"search query of google\", \"required\": true}] Format the arguments as a JSON object.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can be repeated zero or more times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: 加拿大2023年人口统计数字是多少？\n"
     ]
    }
   ],
   "source": [
    "TOOL_DESC = \"\"\"{name_for_model}: Call this tool to interact with the {name_for_human} API. What is the {name_for_human} API useful for? {description_for_model} Parameters: {parameters} Format the arguments as a JSON object.\"\"\"\n",
    "\n",
    "REACT_PROMPT = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tool_descs}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can be repeated zero or more times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {query}\"\"\"\n",
    "\n",
    "def build_planning_prompt(TOOLS, query):\n",
    "    tool_descs = []\n",
    "    tool_names = []\n",
    "    for info in TOOLS:\n",
    "        tool_descs.append(\n",
    "            TOOL_DESC.format(\n",
    "                name_for_model=info['name_for_model'],\n",
    "                name_for_human=info['name_for_human'],\n",
    "                description_for_model=info['description_for_model'],\n",
    "                parameters=json.dumps(\n",
    "                    info['parameters'], ensure_ascii=False),\n",
    "            )\n",
    "        )\n",
    "        tool_names.append(info['name_for_model'])\n",
    "    tool_descs = '\\n\\n'.join(tool_descs)\n",
    "    tool_names = ','.join(tool_names)\n",
    "\n",
    "    prompt = REACT_PROMPT.format(tool_descs=tool_descs, tool_names=tool_names, query=query)\n",
    "    return prompt\n",
    "\n",
    "prompt_1 = build_planning_prompt(TOOLS[0:1], query=\"加拿大2023年人口统计数字是多少？\")\n",
    "print(prompt_1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T15:12:15.144185Z",
     "start_time": "2024-01-14T15:12:15.142760Z"
    }
   },
   "id": "7ff0415672a304e1",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 设置模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66a4085cfca965b9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "023b0e5c8ec147608b53adc1e570e9b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checkpoint = \"F:\\\\llms\\\\Qwen-1_8B-Chat/\"\n",
    "# checkpoint = \"/Users/johnllm/llms/Qwen-1_8B-Chat/\"\n",
    "checkpoint = \"/Users/johnllm/llms/Qwen-7B-Chat/\"\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "MODEL = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"auto\", trust_remote_code=True).eval()\n",
    "MODEL.generation_config = GenerationConfig.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "MODEL.generation_config.do_sample = False  # greedy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T15:12:27.500940Z",
     "start_time": "2024-01-14T15:12:17.358268Z"
    }
   },
   "id": "c6965baa3e08769c",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnllm/miniforge3/envs/hgf/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/Users/johnllm/miniforge3/envs/hgf/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:377: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 我需要搜索相关信息。\n",
      "Action: Search\n",
      "Action Input: {\"query\": \"加拿大 2023 年人口统计数字\"}\n",
      "Observation:\n"
     ]
    }
   ],
   "source": [
    "stop = [\"Observation:\", \"Observation:\\n\"]\n",
    "react_stop_words_tokens = [TOKENIZER.encode(stop_) for stop_ in stop]\n",
    "response_1, _ = MODEL.chat(TOKENIZER, prompt_1, history=None, stop_words_ids=react_stop_words_tokens)\n",
    "print(response_1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T15:12:37.428903Z",
     "start_time": "2024-01-14T15:12:34.290607Z"
    }
   },
   "id": "3b318f54694f3e64",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 第二步：从千问的输出中解析需要使用的工具和入参，并调用对应工具"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6b84ad2c08222e4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"query\": \"加拿大 2023 年人口统计数字\"}\n",
      "['【星島綜合報道】加拿大2023年第三季度人口增長超過43萬，是自1957年以來人口增長最快的季度。加拿大統計局今（19日）發佈最新數據，截至10月1日，該 ...']\n"
     ]
    }
   ],
   "source": [
    "def parse_latest_plugin_call(text: str) -> Tuple[str, str]:\n",
    "    i = text.rfind('\\nAction:')\n",
    "    j = text.rfind('\\nAction Input:')\n",
    "    k = text.rfind('\\nObservation:')\n",
    "    if 0 <= i < j:  # If the text has `Action` and `Action input`,\n",
    "        if k < j:  # but does not contain `Observation`,\n",
    "            # then it is likely that `Observation` is ommited by the LLM,\n",
    "            # because the output text may have discarded the stop word.\n",
    "            text = text.rstrip() + '\\nObservation:'  # Add it back.\n",
    "            k = text.rfind('\\nObservation:')\n",
    "    if 0 <= i < j < k:\n",
    "        plugin_name = text[i + len('\\nAction:'):j].strip()\n",
    "        plugin_args = text[j + len('\\nAction Input:'):k].strip()\n",
    "        return plugin_name, plugin_args\n",
    "    return '', ''\n",
    "\n",
    "def use_api(tools, response):\n",
    "    use_toolname, action_input = parse_latest_plugin_call(response)\n",
    "    if use_toolname == \"\":\n",
    "        return \"no tool founds\"\n",
    "\n",
    "    used_tool_meta = list(filter(lambda x: x[\"name_for_model\"] == use_toolname, tools))\n",
    "    if len(used_tool_meta) == 0:\n",
    "        return \"no tool founds\"\n",
    "    \n",
    "    api_output = used_tool_meta[0][\"tool_api\"](action_input)\n",
    "    return api_output\n",
    "\n",
    "api_output = use_api(TOOLS, response_1)\n",
    "print(api_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T15:12:41.730925Z",
     "start_time": "2024-01-14T15:12:39.680080Z"
    }
   },
   "id": "f7b0ec12c8db15ee",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 第三步：让千问根据工具返回结果继续作答"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "563857f6fe0b113d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Search: Call this tool to interact with the google search API. What is the google search API useful for? useful for when you need to answer questions about current events. Parameters: [{\"name\": \"query\", \"type\": \"string\", \"description\": \"search query of google\", \"required\": true}] Format the arguments as a JSON object.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can be repeated zero or more times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: 加拿大2023年人口统计数字是多少？Thought: 我需要搜索相关信息。\n",
      "Action: Search\n",
      "Action Input: {\"query\": \"加拿大 2023 年人口统计数字\"}\n",
      "Observation: ['【星島綜合報道】加拿大2023年第三季度人口增長超過43萬，是自1957年以來人口增長最快的季度。加拿大統計局今（19日）發佈最新數據，截至10月1日，該 ...'] Thought: 这个信息似乎并不包含我需要的人口统计数据。\n",
      "Final Answer: 对不起，我无法提供加拿大2023年人口统计数据。建议您查阅相关政府部门或媒体发布的官方数据。\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = prompt_1 + response_1 + ' ' + api_output\n",
    "stop = [\"Observation:\", \"Observation:\\n\"]\n",
    "react_stop_words_tokens = [TOKENIZER.encode(stop_) for stop_ in stop]\n",
    "response_2, _ = MODEL.chat(TOKENIZER, prompt_2, history=None, stop_words_ids=react_stop_words_tokens)\n",
    "print(prompt_2, response_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T15:12:55.813145Z",
     "start_time": "2024-01-14T15:12:47.771590Z"
    }
   },
   "id": "5e3dcaaf79af9dbb",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 总结 - 串联起整个流程"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc6e96423dd3a680"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def main(query, choose_tools):\n",
    "    prompt = build_planning_prompt(choose_tools, query) # 组织prompt\n",
    "    print(prompt)\n",
    "    stop = [\"Observation:\", \"Observation:\\n\"]\n",
    "    react_stop_words_tokens = [TOKENIZER.encode(stop_) for stop_ in stop]\n",
    "    response, _ = MODEL.chat(TOKENIZER, prompt, history=None, stop_words_ids=react_stop_words_tokens)\n",
    "\n",
    "    while \"Final Answer:\" not in response: # 出现final Answer时结束\n",
    "        api_output = use_api(choose_tools, response) # 抽取入参并执行api\n",
    "        api_output = str(api_output) # 部分api工具返回结果非字符串格式需进行转化后输出\n",
    "        if \"no tool founds\" == api_output:\n",
    "            break\n",
    "        print(\"\\033[32m\" + response + \"\\033[0m\" + \"\\033[34m\" + ' ' + api_output + \"\\033[0m\")\n",
    "        prompt = prompt + response + ' ' + api_output # 合并api输出\n",
    "        response, _ = MODEL.chat(TOKENIZER, prompt, history=None, stop_words_ids=react_stop_words_tokens) # 继续生成\n",
    "\n",
    "    print(\"\\033[32m\" + response + \"\\033[0m\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T15:12:59.653237Z",
     "start_time": "2024-01-14T15:12:59.649174Z"
    }
   },
   "id": "46792da2d248a827",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Search: Call this tool to interact with the google search API. What is the google search API useful for? useful for when you need to answer questions about current events. Parameters: [{\"name\": \"query\", \"type\": \"string\", \"description\": \"search query of google\", \"required\": true}] Format the arguments as a JSON object.\n",
      "\n",
      "Math: Call this tool to interact with the Wolfram Alpha API. What is the Wolfram Alpha API useful for? Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Parameters: [{\"name\": \"query\", \"type\": \"string\", \"description\": \"the problem to solved by Wolfram Alpha\", \"required\": true}] Format the arguments as a JSON object.\n",
      "\n",
      "Arxiv: Call this tool to interact with the arxiv API. What is the arxiv API useful for? A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Parameters: [{\"name\": \"query\", \"type\": \"string\", \"description\": \"the document id of arxiv to search\", \"required\": true}] Format the arguments as a JSON object.\n",
      "\n",
      "python: Call this tool to interact with the python API. What is the python API useful for? A Python shell. Use this to execute python commands. When using this tool, sometimes output is abbreviated - Make sure it does not look abbreviated before using it in your answer. Don't add comments to your python code. Parameters: [{\"name\": \"query\", \"type\": \"string\", \"description\": \"a valid python command.\", \"required\": true}] Format the arguments as a JSON object.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search,Math,Arxiv,python]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can be repeated zero or more times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: 使用python对下面的列表进行排序： [2, 4135, 523, 2, 3]\n",
      "```py\n",
      "lst = [2, 4135, 523, 2, 3]\n",
      "sorted_lst = sorted(lst)\n",
      "sorted_lst\n",
      "```\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 20\u001B[0m\n\u001B[1;32m     18\u001B[0m choose_tools \u001B[38;5;241m=\u001B[39m TOOLS \u001B[38;5;66;03m# 选择备选工具\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m=\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m10\u001B[39m)\n\u001B[0;32m---> 20\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchoose_tools\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[8], line 9\u001B[0m, in \u001B[0;36mmain\u001B[0;34m(query, choose_tools)\u001B[0m\n\u001B[1;32m      6\u001B[0m response, _ \u001B[38;5;241m=\u001B[39m MODEL\u001B[38;5;241m.\u001B[39mchat(TOKENIZER, prompt, history\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, stop_words_ids\u001B[38;5;241m=\u001B[39mreact_stop_words_tokens)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinal Answer:\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m response: \u001B[38;5;66;03m# 出现final Answer时结束\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m     api_output \u001B[38;5;241m=\u001B[39m \u001B[43muse_api\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchoose_tools\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# 抽取入参并执行api\u001B[39;00m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;66;03m# api_output = str(api_output) # 部分api工具返回结果非字符串格式需进行转化后输出\u001B[39;00m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno tool founds\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m==\u001B[39m api_output:\n",
      "Cell \u001B[0;32mIn[6], line 26\u001B[0m, in \u001B[0;36muse_api\u001B[0;34m(tools, response)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(used_tool_meta) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno tool founds\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 26\u001B[0m api_output \u001B[38;5;241m=\u001B[39m \u001B[43mused_tool_meta\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtool_api\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m api_output\n",
      "Cell \u001B[0;32mIn[1], line 28\u001B[0m, in \u001B[0;36mtool_wrapper_for_qwen.<locals>.tool_\u001B[0;34m(query)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtool_\u001B[39m(query):\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;28mprint\u001B[39m(query)\n\u001B[0;32m---> 28\u001B[0m     query \u001B[38;5;241m=\u001B[39m \u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquery\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tool\u001B[38;5;241m.\u001B[39mrun(query)\n",
      "File \u001B[0;32m~/miniforge3/envs/hgf/lib/python3.9/json/__init__.py:346\u001B[0m, in \u001B[0;36mloads\u001B[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[1;32m    341\u001B[0m     s \u001B[38;5;241m=\u001B[39m s\u001B[38;5;241m.\u001B[39mdecode(detect_encoding(s), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msurrogatepass\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    344\u001B[0m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    345\u001B[0m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[0;32m--> 346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_decoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    348\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m JSONDecoder\n",
      "File \u001B[0;32m~/miniforge3/envs/hgf/lib/python3.9/json/decoder.py:337\u001B[0m, in \u001B[0;36mJSONDecoder.decode\u001B[0;34m(self, s, _w)\u001B[0m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode\u001B[39m(\u001B[38;5;28mself\u001B[39m, s, _w\u001B[38;5;241m=\u001B[39mWHITESPACE\u001B[38;5;241m.\u001B[39mmatch):\n\u001B[1;32m    333\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    containing a JSON document).\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 337\u001B[0m     obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_w\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    338\u001B[0m     end \u001B[38;5;241m=\u001B[39m _w(s, end)\u001B[38;5;241m.\u001B[39mend()\n\u001B[1;32m    339\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m end \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(s):\n",
      "File \u001B[0;32m~/miniforge3/envs/hgf/lib/python3.9/json/decoder.py:355\u001B[0m, in \u001B[0;36mJSONDecoder.raw_decode\u001B[0;34m(self, s, idx)\u001B[0m\n\u001B[1;32m    353\u001B[0m     obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscan_once(s, idx)\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m--> 355\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpecting value\u001B[39m\u001B[38;5;124m\"\u001B[39m, s, err\u001B[38;5;241m.\u001B[39mvalue) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj, end\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# 请尽可能控制备选工具数量\n",
    "# query = \"加拿大2022年的人口数量有多少？\" # 所提问题\n",
    "# choose_tools = TOOLS # 选择备选工具\n",
    "# print(\"=\" * 10)\n",
    "# main(query, choose_tools)\n",
    "# \n",
    "# query = \"求解方程 2x+5 = -3x + 7\" # 所提问题\n",
    "# choose_tools = TOOLS # 选择备选工具\n",
    "# print(\"=\" * 10)\n",
    "# main(query, choose_tools)\n",
    "# \n",
    "# query = \"编号是1605.08386的论文讲了些什么？\" # 所提问题\n",
    "# choose_tools = TOOLS # 选择备选工具\n",
    "# print(\"=\" * 10)\n",
    "# main(query, choose_tools)\n",
    "\n",
    "query =\"使用python对下面的列表进行排序： [2, 4135, 523, 2, 3]\"\n",
    "choose_tools = TOOLS # 选择备选工具\n",
    "print(\"=\" * 10)\n",
    "main(query, choose_tools)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T15:13:13.682433Z",
     "start_time": "2024-01-14T15:13:01.098257Z"
    }
   },
   "id": "11cfe3a3f3d179a4",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 2, 3, 523, 4135]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [2, 4135, 523, 2, 3]\n",
    "sorted_lst = sorted(lst)\n",
    "sorted_lst"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T12:34:26.333659Z",
     "start_time": "2024-01-13T12:34:26.306159Z"
    }
   },
   "id": "997c3a22c1edc727",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "459ab607c8de4ec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
